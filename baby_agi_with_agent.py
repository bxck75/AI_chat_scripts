# -*- coding: utf-8 -*-
"""baby_agi_with_agent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/langchain-ai/langchain/blob/master/cookbook/baby_agi_with_agent.ipynb

# BabyAGI with Tools

This notebook builds on top of [baby agi](baby_agi.html), but shows how you can swap out the execution chain. The previous execution chain was just an LLM which made stuff up. By swapping it out with an agent that has access to tools, we can hopefully get real reliable information

## Install and Import Required Modules
"""

from typing import Optional
from rich import print as rp
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain_experimental.autonomous_agents import BabyAGI
from components.hugging_chat_wrapper import HuggingChatWrapper,HuggingFaceEmbeddings
from langchain_core.runnables.base import Runnable
from langchain.agents.utils import validate_tools_single_input
from langchain_community.docstore import Wikipedia
from langchain_core.prompts import PromptTemplate
from PyQt6.QtWidgets import QWidget, QVBoxLayout, QHBoxLayout, QPushButton, QTextEdit, QFileDialog, QLabel
from langchain_community.agent_toolkits import FileManagementToolkit
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.retrievers import TimeWeightedVectorStoreRetriever
from langchain_core.documents import Document
from PyQt6.QtWidgets import ( QApplication, QMainWindow, QWidget, QVBoxLayout, QTabWidget,  QTextEdit, QLineEdit, QPushButton)
from langchain.agents import Tool, AgentExecutorIterator,AgentType, initialize_agent,AgentExecutor
from langchain_community.agent_toolkits.load_tools import load_tools
from langchain.agents import create_react_agent,create_self_ask_with_search_agent
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_experimental.tools.python.tool import PythonAstREPLTool
from langchain_experimental.llm_bash.bash import BashProcess
from langchain_community.tools import ShellTool
from langchain.output_parsers.json import SimpleJsonOutputParser
from langchain_core.output_parsers.string import StrOutputParser
from langchain.memory import ConversationBufferMemory,ConversationSummaryBufferMemory,CombinedMemory
from langchain_community.tools.file_management import (
        CopyFileTool,
        DeleteFileTool,
        FileSearchTool,
        ListDirectoryTool,
        MoveFileTool,
        ReadFileTool,
        WriteFileTool,
    )
from langchain_community.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper
from langchain_community.tools.wikidata.tool import WikidataAPIWrapper, WikidataQueryRun
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_community.tools import WikipediaQueryRun
from langchain_community.utilities import WikipediaAPIWrapper
wrapper=HuggingChatWrapper('baby_agi')
"""## Connect to the Vector Store

Depending on what vectorstore you use, this step may look different.
"""


class RunnableChatBot(Runnable):
    def __init__(self, chatbot):
        self.chatbot = chatbot
    
    def invoke(self, input, config=None, **kwargs):
        #rp(f"input:{input.text}")
        msgs=input.to_messages()
        #rp(f"msgs:{msgs}")
        adjective = msgs[0].content#['adjective']
        rp(f"adjective:{adjective}")

        return str(self.chatbot.chat(adjective))

llm=RunnableChatBot(wrapper.set_bot(system_prompt="""You are a python expert and our task is to develop code with the users input as guide. 
                                        Only output the fullly implemented code.""", model_id=0))


# Commented out IPython magic to ensure Python compatibility.
# %pip install faiss-cpu > /dev/null
# %pip install google-search-results > /dev/null
from langchain.docstore import InMemoryDocstore
from langchain_community.vectorstores import FAISS

# Define your embedding model
embeddings_model = HuggingFaceEmbeddings()
# Initialize the vectorstore as empty
import faiss

embedding_size = 384
index = faiss.IndexFlatL2(embedding_size)
vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})

"""## Define the Chains

BabyAGI relies on three LLM chains:
- Task creation chain to select new tasks to add to the list
- Task prioritization chain to re-prioritize tasks
- Execution Chain to execute the tasks


NOTE: in this notebook, the Execution chain will now be an agent.
"""
from dotenv import load_dotenv,find_dotenv
load_dotenv(find_dotenv())
import os
from langchain.agents import AgentExecutor, Tool, ZeroShotAgent
from langchain.chains import LLMChain
from langchain_community.utilities import SerpAPIWrapper

todo_prompt = PromptTemplate.from_template(
    "You are a planner who is an expert at coming up with a todo list for a given objective. Come up with a todo list for this objective: {objective}"
)
todo_chain = LLMChain(llm=llm, prompt=todo_prompt)
search = SerpAPIWrapper(serpapi_api_key=os.getenv('HUGGINGFACEHUB_API_TOKEN'))
wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())
ddg = DuckDuckGoSearchRun(api_wrapper=DuckDuckGoSearchAPIWrapper())


# Define tools
file_copy = CopyFileTool()
dir_list = ListDirectoryTool()
read_file = ReadFileTool()
write_file = WriteFileTool()
move_file = MoveFileTool()
file_search = FileSearchTool()
bash_shell = ShellTool()
python_repl = PythonAstREPLTool()

tools =[
    Tool(
        name = 'Copy File',
        func = file_copy.run,
        verbose=True,
        description = '''
        A tool to copy files from one location to another.
        Input should be a dictionary with 'source' and 'destination' keys.
        '''
    ),
    Tool(
        name = 'List Directory',
        func = file_copy.run,
        verbose=True,
        description = '''
        A tool to list files in a directory.
        Input should be a dictionary with 'directory' key.
        '''
    ),
    Tool(
        name = 'List Directory',
        func = file_copy.run,
        verbose=True,
        description = '''
        A tool to read a file and return its content.
        Input should be a dictionary with 'file' key.
        '''
    ),
    Tool(
        name = 'Write File',
        func = file_copy.run,
        verbose=True,
        description = '''
        A tool to write content to a file.
        Input should be a dictionary with 'content' and 'file' keys.
        '''
    ),
    Tool(
        name = 'Move File',
        func = move_file.run,
        verbose=True,
        description = '''
        A tool to move files from one location to another.
        Input should be a dictionary with 'source' and 'destination' keys.
        '''
    ),
    Tool(
        name = 'File Search',
        func = file_search.run,
        verbose=True,
        description = '''
        A tool to search for files.
        Input should be a dictionary with 'query' and 'directory' keys.
        '''
    ),
    Tool(
        name = 'Python REPL',
        func = python_repl.run,
        handle_tool_error=True,
        handle_validation_error=True,
        verbose=True,
        description = '''
        A Python shell. Use this to execute python commands. 
        Input should be a valid python command. 
        When using this tool, sometimes output is abbreviated - make sure 
        it does not look abbreviated before using it in your answer.
        '''
    ),
    Tool(
        name = 'DuckDuckGo Search',
        func = ddg.run,
        verbose=True,
        description = '''
        A wrapper around DuckDuckGo Search. 
        Useful for when you need to answer questions about current events. 
        Input should be a search query.
        '''
    ),
    Tool(
        name = 'Bash Shell',
        func = bash_shell.run,
        verbose=True,
        description = '''
            A tool to run bash commands.
            Use this to execute bash commands.
            Input should be a string with the bash command.
            Example: 'mkdir new_project && cd new_project && ls -l'
        '''
    ),
    Tool(
        name="Search",
        func=search.run,
        description="useful for when you need to answer questions about current events",
    ),
    Tool(
        name="TODO",
        func=todo_chain.run,
        description="useful for when you need to come up with todo lists. Input: an objective to create a todo list for. Output: a todo list for that objective. Please be very clear what the objective is!",
    ),
]


wikitool = Tool( name="Intermediate Answer",func=wikipedia.run,description='''
                                            A wrapper around Wikipedia Search 
                                            Useful for when you need to answer questions about current events. 
                                            Input should be a search query'''
         )
""" ddg = Tool( name="Intermediate Answer",func=ddg.run, description='''
                                            A wrapper around DuckDuckGo Search. 
                                            Useful for when you need to answer questions about current events. 
                                            Input should be a search query.'''
         ) """

prefix = """You are an AI who performs one task based on the following objective: {objective}. Take into account these previously completed tasks: {context}."""
suffix = """Question: {task}
{agent_scratchpad}"""
prompt = ZeroShotAgent.create_prompt(
    tools,
    prefix=prefix,
    suffix=suffix,
    input_variables=["objective", "task", "context", "agent_scratchpad"],
)
from typing import Any, List, Mapping, Optional
from langchain_core.language_models.llms import LLM
from langchain_core.pydantic_v1 import Field
from components.hugging_chat_wrapper import HuggingChatWrapper

class HuggingChatLLM(LLM):
    project_name: str = Field(default="AgenticDashboard")
    system_prompt: str = Field(default="You are a helpful AI assistant.")
    model_id: int = Field(default=0)
    
    _chatbot: Optional[HuggingChatWrapper] = None

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self._chatbot = HuggingChatWrapper(project_name=self.project_name)
        self._chatbot.set_bot(system_prompt=self.system_prompt, model_id=self.model_id)

    @property
    def _llm_type(self) -> str:
        return "huggingchat"

    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[Any] = None,
        **kwargs: Any,
    ) -> str:
        response = self._chatbot.chat(prompt)
        if stop:
            for stop_sequence in stop:
                if stop_sequence in response:
                    response = response[:response.index(stop_sequence)]
        return response

    @property
    def _identifying_params(self) -> Mapping[str, Any]:
        return {
            "project_name": self.project_name,
            "system_prompt": self.system_prompt,
            "model_id": self.model_id,
        }


llm_chain = LLMChain(llm=llm, prompt=prompt)
tool_names = [tool.name for tool in tools]
agent = ZeroShotAgent(llm_chain=llm_chain, allowed_tools=tool_names)
agent_executor = AgentExecutor.from_agent_and_tools(
    agent=agent, tools=tools, verbose=True
)

"""### Run the BabyAGI

Now it's time to create the BabyAGI controller and watch it try to accomplish your objective.
"""

OBJECTIVE = "Write a weather report for SF today"

# Logging of LLMChains
verbose = True
# If None, will keep on going forever
max_iterations: Optional[int] = 10
baby_agi = BabyAGI.from_llm(
    llm=llm,
    vectorstore=vectorstore,
    task_execution_chain=agent_executor,
    verbose=verbose,
    max_iterations=max_iterations,
)

baby_agi({"objective": OBJECTIVE})

